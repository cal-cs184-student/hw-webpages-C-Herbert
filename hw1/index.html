<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Name: Charlie Herbert </div>

		<br>

		Link to webpage: (TODO) <a href="https://cal-cs184-student.github.io/hw-webpages-C-Herbert/">cal-cs184-student.github.io/hw-webpages-C-Herbert</a>
		
		<br>

		Link to GitHub repository: (TODO) <a href="https://github.com/cal-cs184-student/hw-webpages-C-Herbert">github.com/cal-cs184-student/hw-webpages-C-Herbert</a>

		<figure>
			<img src="lion.jpg" alt="Lion" style="width:50%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.
        
        <p>
        This homework involved implementing several useful features for rendering triangles to the screen. 
        These include rasterization, barycentric color interpolation, several texture sampling techniques, and texture mipmap levels. 
        Together, these features allow us to draw textured triangles at any scale while minimizing sampling artifacts. 
        Additionally, rotation, translation, and scaling matricies were implemented with homogenous coordinates to allow for easy manipulation of triangles.
        </p>

        <p>
        While completing this assignment I... (interesting things here)
        </p>


		<h2>Task 1: Drawing Single-Color Triangles</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
        <p>
            While the previous rasterization algorithm does a decent job of rendering the triangle's shape, there are notable sampling artifacts.
            These artifacts occur as a result of our sampling frequency being too low to properly capture the high-frequency boundries of the triangle.
            In some cases, such as long, thin triangles, we fail to draw anything at all, resulting in disconnected or greatly shortened triangles.
            Since we can't produce physical pixels with infinite resolution, we must instead improve our sampling algorithm.
            To do this, we'll use antialiasing via supersampling, which will approximate limiting the maximum frequency in our image to a value we can render.
        </p>
        <p>
            First, to support antialiasing by supersampling, we need to adjust how the program's sample buffer stores information. 
            Whenever we set the sample rate of the program, we should also set the size of the sample buffer to be equal to \(width_{screen} * height_{screen} * s_{rate}\), where \(width_{screen}, height_{screen}\) are the screen's pixel dimensions, and \(s_{rate}\) is the supersampling rate we'll be using.
            This ensures that we have \(s_{rate}\) color slots to write to for each pixel, which is sufficient to store our supersampled data.
        </p>
		<p>
            Implementing supersampling requires some small modifications to the rasterization algorithm itself. 
            Before iterating over the pixels of the triangle, my implementation precomputes 3 values that are used for every the supersample position calculation.
            These are the "sample dimension", which is simply the number samples along a single axis, the "sample step", and the "half step".
            The sample step is calculated as 1 divided by 1 plus the sample dimension, since we want all of our supersample positions to be within the pixel we are sampling.
            The half step is simply half the sample step, and is used as a constant offset applied to all supersampling operations.
        </p>
        <p>
            The pixel positions of the triangle are iterated over as in the standard rasterization process.
            However, instead of checking if just the center of the pixel is in the triangle, we iterate over and check each of the super sample positions within the pixel.
            For simplicity, the iteration over the supersamples is done with as a nested pair of for loops, with one for each axis.
            Using the counter variables of each loop, we can calculate the super sample position as follows:
            \[ (x + x_s * s_{step} + s_{hs},  y + y_s * s_{step} + s_{hs} ) \]
            Where \(x,y\) are the initial pixel coordinates from rasterizing, \(x_s,y_s\) are the loop indicies for their respective axes, and \(s_{step},s_{hs}\) are the precomputed step and half step values.
            After performing the same 'in triangle' check as before, the appropriate color is written to the sample buffer.
            The supersample's index in the buffer is calculated as \( (x + y * width_{screen}) * s_{rate} + x_s + floor(s_{dim}) * y_s \),
            where \(s_{rate}\) is the sample rate provided by the program, and \(s_{dim}\) is the precomputed sample dimension.
        </p>
        <p>
            Finally, when drawing a pixel, the results of this supersampling process are applied by averaging supersampled color values for that pixel to produce an overall color. Note that this means we average a total of \(s_{rate}\) colors for each pixel drawn to the screen.
        </p>

		<h2>Task 3: Transforms</h2>
        <p>
            For this task, I was initially trying to pose the robot so that it was hanging from the top of the frame, like monkey bars. 
            Though, it ended up looking like the robot was sort of jumping, which I also liked. 
            I also changed the colors to blue and gold, since that seemed much more appropriate than red.
        </p>
        
        <img src="robot.png" alt="Jumping Robot" style="width:50%"/>

		<h2>Task 4: Barycentric coordinates</h2>
        <p>
        Barycentric coordinates are a coordinate system which allows us to represent any arbitrary point as a linear combination of 3 other points, forming a triangle. This is useful for interpolating values like color across the surface of a triangle, as well as switching between screen and texture space sample coordinates. To demonstrate barycentric coordinates, we have the following image:
        </p>
        (IMG)
        <p>
        In this triangle, we have a red, green, and blue corner. If we treat the 'proportion' of each corner in the samples' barycentric coordinates as the respective red, green, and blue values of the sample, we get the above image. With this understanding, it is clear that every sample location inside the triangle is some combination of the three corner positions.
        </p>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
        <p>
            While drawing triangles with solid or interpolated colors is nice, pixel sampling allows us to apply a texture across the surface of a triangle. 
            This makes it much easier to create significantly more detail with the same amount of geometry.
            At a high level, pixel sampling involves taking some coordinates, transforming them to the space of a discrete function, and using the sample of that function at the transformed position as the value of the posiiton in the original space.
            In our 'texture mapping' case, the discrete function will be a texture, with pixels defined at integer coordinates for some rectangular width and height. 
            Additionally, we'll be transforming from the screen space to the texture's own space to sample the texture's pixels.
        </p>
        <p>
            We'll be implementing two pixel sampling methods: nearest-neighbor and bilinear.
            Nearest-neightbor simply rounds the transformed coordinates to the nearest pixel coordinates in the texture, and returns the color value of that pixel.
            Bilinear sampling instead performs a linear interpolation on the closest texture pixels the transformed coordinate lies between. 
            This provides a smoother result, as the returned color is a weighted average of the surrounding pixels.
        </p>
        <p>
            To actually implement pixel sampling, we'll re-use the barycentric calculations from Task 4. 
            Since our triangle-rasterizing function is given both screen space x,y coordinates and texture space u,v coordinates, a barycentric representation of a sample's coordinates will allow us to easily transform between the two spaces.
            This is because the 'proportion' of each triangle point in a coordinate should remain the same, regardless of any rotation, scaling, or translation effects resulting from transforming between the two spaces.
            Then, just like in task 2, we precompute some values, in this case transformation matricies, apply the barycentric transformation to every sample point, and sample the specified texture at that point, using one of the above coordinates.
            Note that, when implementing the texture sampling functions, we have to scale provided u,v coordinates by the texture's width and height, respectively, as the u,v coordinates are provided in a normalized format.
        </p>

        (IMAGES)

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
        <p>
            The bilinear mode of our texture mapping implementation handles magnified textures quite well. 
            However, we don't yet have a solution for minified textures.
            When we sample a large texture at only a few points, we quickly run into artifacts like Moire patterns due to our sampling rate being much lower than highest frequencies present within the image.
            In other words, having a large texture cover only a few screen pixels results in us exceeding the Nyquist frequency. 
        </p>
        <p>
            To fix this, one option is to reduce the presence of high frequencies in the texture we are sampling when it is being used to cover only a small area.
            This is where mipmaps and level sampling come in, as they allow us to do exactly that.
            Mipmaps are essentially lower resolution copies of a texture, which have been downsampled to incrementally eliminate higher frequencies.
            For each texture, we'll compute several 'levels' of mipmaps, each downsampled further than the last.
            Then, when rasterizing, we can select which level of mipmap to sample from depending on the area covered by the texture in screen space.
            This selection process is known as level sampling.
        </p>
        <p>
            To actually implement level sampling, we have to be able to do two things. 
            First is determining which mipmap level should be used for a given sample. 
            To do this, we pass in not just the uv coordinates of the sample position, but also the uv coordinates of that position shifted by 1 pixel along the screen space axes.
            Thus, we'll also pass in two copies of the uv coordinates, one shifted by 1 along the x-axis, and one shifted by 1 along the y-axis.
            Using the difference of the shifted uv coordinates and the original uv sample coordinates, we can determine how many pixels a one pixel step in the screen space covers in the texture space, and choose a downsampled mipmap accordingly.
            Since the xy and uv axes may not line up exactly, we focus on the magnitudes of the 'step' vectors in texture space. 
            By choosing the maximum of these vectors, we guarantee that our selected mipmap will not have frequencies exceeding screen's sampling rate.
            Also, since our downsampling implementation halves the resolution of the textures with each level, we want to take the base 2 logarithm of this maximum to get an accurate magnitude-to-level conversion.
            However, this leaves us with a potentially fractional level value.
            To fix this, we can either round or interpolate between levels.
        </p>
        <p>
            Rounding, or nearest-level approximation is straightforward. 
            We just take the ceiling of the floating-point level value produced in the previous steps, and sample from that mipmap texture as in Task 5.
            Note that we use the ceiling here instead of true rounding, since we need to ensure that all frequencies present in the mipmap are below the Nyquist threshold.
            Additionally, we scale the uv coordinates by the width and height of the mipmap, instead of the overall texture's dimensions.
        </p>
        <p>
            If we instead want to linearly interpolate between the integer levels surrounding our floating point value, we begin by sampling both the levels at the floor and ceiling of the initial floating-point level value.
            This proceeds as in Task 5, using either nearest-neighbor or bilinear sampling for both levels.
            Once we have both colors, we linearly interpret between them, using the intial floating point value.


        </p>


		<h2>(Optional) Task 7: Extra Credit - Draw Something Creative!</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>