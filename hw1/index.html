<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Name: Charlie Herbert </div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-C-Herbert/">cal-cs184-student.github.io/hw-webpages-C-Herbert</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/hw-webpages-C-Herbert">github.com/cal-cs184-student/hw-webpages-C-Herbert</a>

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.
        
        <p>
        This homework involved implementing several useful features for rendering triangles to the screen. 
        These include rasterization, barycentric color interpolation, several texture sampling techniques, and texture mipmap levels. 
        Together, these features allow us to draw textured triangles at any scale while minimizing sampling artifacts. 
        Additionally, rotation, translation, and scaling matricies were implemented with homogenous coordinates to allow for easy manipulation of triangles.
        </p>

        <p>
        While completing this assignment I... (interesting things here)
        </p>


		<h2>Task 1: Drawing Single-Color Triangles</h2>
		<p>
            At a high level, rasterizing triangles involves picking a set of points to sample, checking if these points are in the triangle, and then assigning that position the triangle's color if they are inside.
            Since we want to draw the colored samples to a screen, the set of points in our case will be an evenly-spaced grid with dimensions corresponding to those of the screen/window.
            Each sample will then correspond to one screen pixel.
            While we could iterate over the entire sample space for every triangle we want to rasterize, this would be highly inefficient.
            Thus, we'll use the bounding box of the triangle to preemptively exclude certain sample points depending on whether the triangle could feasibly contain them.
            To do this, when rasterizing a triangle, we only iterate over sample points within the bounding box.
            This bounding box is easily calculated as a box with a 'lower' corner consisting of the minimum x and y coordinates of any point on the triangle, and an 'upper' corner consisting of the maximum x and y coordinates.
            Note that either corner's x and y coordinates don't have to come from the same point of the triangle, they just have to be the max/min of their respective dimensions.
            With these corner points in hand, we simply iterate over all sample points from the lower corner to the upper corner, checking if each is in the triangle or not.
            If a sample point is in the triangle, we write the color of said triangle to a buffer with an index corresponding to the sample's position.
        </p>
        <p>
            There are a number of methods we can use to check if a point is inside a triangle, though the one I chose for my implementation was to use the dot product of a sample point and the normal vectors of the triangle's sides.
            By calculating the delta vector of a sample point with one of the vertices of a side, then taking the dot product of that vector and the side's normal vector, we can use the sign of the result to determine if the point is in the triangle or not.
            If the dot product is nonnegative, and the triangle winds counter clockwise, then the sample is on the 'inside'-side of that edge of the triangle.
            Repeating this for each side of the triangle, we have that the point is only inside the triangle if all dot products are greater than or equal to zero.
            Note that 'nonnegative' flips to 'nonpositive' if the triangle winds in a clockwise direction.
            Either way, this covers all the steps needed to rasterize a triangle.
            The process ultimately allows us to take in an abstract geometric representation of a triangle and produce an image of it using only the discrete number of pixels on a screen.
            While the bounding box approach isn't great, it is a good starting point, which I'll improve upon in the next section.
        </p>

        <h3>Rasterization Extra Credit:</h3>
        <p>
            While I initially went with the above bounding-box rasterization algorithm, I felt this scheme was wasteful performance-wise and wanted to improve it.
            Figuring out how to do this took a couple tries, but I eventually ended up with the following algorithm.
            The basic idea is to scan from the bottom of the triangle to the top of the triangle and, at each step, determine the leftmost and rightmost extents possibly covered by the triangle.
            Then, with these extents, we scan from left to right.
            This significantly reduces the number of samples we have to check in comparison to the bounding box case, since we can skip most of the blank area surrounding a triangle within its bounding box.
            Additionally, we don't check any points outside the bounding box, so this algorithm can only improve on the bounding box appraoch.
        </p>
        <p>
            Now, for the algorithm.
            First, for each line segment of the triangle, figure out its maximum and y coordinates.
            Since we're dealing with lines, the maximum and minimum must be one of the two points forming the line.
            While doing this, we also record the overall maximum and minimum y coordinates of the triangle, like in the bounding box case.
            We'll call these \(y_{min}\) and \(y_{max}\), respectively.
        </p>
        <p>
            Once we have these values, we iterate from \(floor(y_{min})\) to \(floor(y_{max})\).
            For each \(y\) value, we begin by iterating over the line segments, checking if \(y\) lands inside their (inclusive) y ranges, which we precomputed.
            Then, if the current \(y\) value does fit inside a segment, we calculate the \(x\) value of that segment at the current \(y\) value.
            While iterating through the valid segments, we track the minimum and maximum x-intersection values we encounter.
            We'll call these \(x_{left}\) and \(x_{right}\), respectively.
            Note that we actually subtract or add the absolute value of the segment's slope when calculating the left and right x positions to ensure we don't miss any partial-pixels when supersampling later on.
            There's also some special logic to handle horizontal lines, which could otherwise result in a division by zero.
            For my implementation, I just added a parallel array of booleans to track which lines are horizontal, and added some extra logic for handling their contributions to the maximum/minimum x search.
            Once we've checked all 3 of the triangle's sides, we proceed by iterating over the x-axis from \(x_{left}\) to \(x_{right}\).
        </p>
        <p>
            At this point, the algorithm proceeds as above, checking if each (x,y) pair is in the triangle or not. 
            While we could almost skip this step, the additional x width added for supersampling requires that we still perform this check.
            Now, for the results. I used <code>basic/test3.svg</code> as the test graphic to render, since it seemed reasonably complicated.
            <div style="display: flex; flex-direction: column; align-items: center;">
                <table style="width: 100%; text-align: center; border-collapse: collapse;">
                  <tr>
                    <td style="text-align: center;">
                      <img src="unoptimized_raster_times.png" width="400px"/>
                      <figcaption>Unoptimized Test Times</figcaption>
                    </td>
                    <td style="text-align: center;">
                      <img src="optimized_raster_times.png" width="400px"/>
                      <figcaption>Optimized Test Times</figcaption>
                    </td>
                  </tr>
                  <tr>
                    <td style="text-align: center;">
                      <img src="unoptimized_test3.png" width="400px"/>
                      <figcaption>Unoptimized Render</figcaption>
                    </td>
                    <td style="text-align: center;">
                      <img src="optimized_test3.png" width="400px"/>
                      <figcaption>Optimized Render</figcaption>
                    </td>
                  </tr>
                </table>
            </div>
        </p>
        <p>
            As we can clearly see from these results, not having to check all of the blank spaces surrounding a triangle in its bounding box offers a significant speed improvement.
            This only becomes more important with increased supersampling levels, since we have to check many more points.
        </p>

		<h2>Task 2: Antialiasing by Supersampling</h2>
        <p>
            While the previous rasterization algorithm does a decent job of rendering the triangle's shape, there are notable sampling artifacts.
            These artifacts occur as a result of our sampling frequency being too low to properly capture the high-frequency boundries of the triangle.
            In some cases, such as long, thin triangles, we fail to draw anything at all, resulting in disconnected or greatly shortened triangles.
            Since we can't produce physical pixels with infinite resolution, we must instead improve our sampling algorithm.
            To do this, we'll use antialiasing via supersampling, which will approximate limiting the maximum frequency in our image to a value we can render.
        </p>
        <p>
            First, to support antialiasing by supersampling, we need to adjust how the program's sample buffer stores information. 
            Whenever we set the sample rate of the program, we should also set the size of the sample buffer to be equal to \(width_{screen} * height_{screen} * s_{rate}\), where \(width_{screen}, height_{screen}\) are the screen's pixel dimensions, and \(s_{rate}\) is the supersampling rate we'll be using.
            This ensures that we have \(s_{rate}\) color slots to write to for each pixel, which is sufficient to store our supersampled data.
        </p>
		<p>
            Implementing supersampling requires some small modifications to the rasterization algorithm itself. 
            Before iterating over the pixels of the triangle, my implementation precomputes 3 values that are used for every the supersample position calculation.
            These are the "sample dimension", which is simply the number samples along a single axis, the "sample step", and the "half step".
            The sample step is calculated as 1 divided by 1 plus the sample dimension, since we want all of our supersample positions to be within the pixel we are sampling.
            The half step is simply half the sample step, and is used as a constant offset applied to all supersampling operations.
        </p>
        <p>
            The pixel positions of the triangle are iterated over as in the standard rasterization process.
            However, instead of checking if just the center of the pixel is in the triangle, we iterate over and check each of the super sample positions within the pixel.
            For simplicity, the iteration over the supersamples is done with as a nested pair of for loops, with one for each axis.
            Using the counter variables of each loop, we can calculate the super sample position as follows:
            \[ (x + x_s * s_{step} + s_{hs},  y + y_s * s_{step} + s_{hs} ) \]
            Where \(x,y\) are the initial pixel coordinates from rasterizing, \(x_s,y_s\) are the loop indicies for their respective axes, and \(s_{step},s_{hs}\) are the precomputed step and half step values.
            After performing the same 'in triangle' check as before, the appropriate color is written to the sample buffer.
            The supersample's index in the buffer is calculated as \( (x + y * width_{screen}) * s_{rate} + x_s + floor(s_{dim}) * y_s \),
            where \(s_{rate}\) is the sample rate provided by the program, and \(s_{dim}\) is the precomputed sample dimension.
        </p>
        <p>
            Finally, when drawing a pixel, the results of this supersampling process are applied by averaging supersampled color values for that pixel to produce an overall color. 
            Note that this means we average a total of \(s_{rate}\) colors for each pixel drawn to the screen.
            After averaging the supersampling results, we have our desired antialiasing effect, as seen below:
        </p>

        <div style="display: flex; flex-direction: column; align-items: center;">
            <table style="width: 100%; text-align: center; border-collapse: collapse;">
              <tr>
                <td style="text-align: center;">
                  <img src="t2_ss1.png" width="400px"/>
                  <figcaption>Sample Rate: 1</figcaption>
                </td>
                <td style="text-align: center;">
                  <img src="t2_ss2.png" width="400px"/>
                  <figcaption>Sample Rate: 4</figcaption>
                </td>
              </tr>
              <tr>
                <td style="text-align: center;">
                  <img src="t2_ss3.png" width="400px"/>
                  <figcaption>Sample Rate: 9</figcaption>
                </td>
                <td style="text-align: center;">
                  <img src="t2_ss4.png" width="400px"/>
                  <figcaption>Sample Rate: 16</figcaption>
                </td>
              </tr>
            </table>
        </div>
        <p>
            As partially explained above, the visible blurring effect around edges of the triangles occurs because we need to either reduce the presence of high frquencies, or increase our sampling rate.
            The supersample-then-average approach does this by first sampling the image at a higher rate, which reduces artifacts caused by high frequencies by increasing the Nyquist frequency.
            This supersampled result is then downsampled to something we can actually display, which is done by averaging the supersampled results on a per-pixel basis.
            The end result is a blurred image, since we've taken away some of the higher frequencies.
            However, this blurred image better represents the underlying geometric object given the constraints of our display.
            </p>
		<h2>Task 3: Transforms</h2>
        <p>
            For this task, I was initially trying to pose the robot so that it was hanging from the top of the frame, like monkey bars. 
            Though, it ended up looking like the robot was sort of jumping, which I also liked. 
            I also changed the colors to blue and gold, since that seemed much more appropriate than red.
        </p>
        
		<figure>
			<img src="robot.png" alt="Jumping Robot" style="width:50%"/>
			<figcaption>Jumping Robot</figcaption>
		</figure>

		<h2>Task 4: Barycentric coordinates</h2>
        <p>
        Barycentric coordinates are a coordinate system which allows us to represent any arbitrary point as a linear combination of 3 other points, forming a triangle. 
        This is useful for interpolating values like color across the surface of a triangle, as well as switching between screen and texture space sample coordinates. 
        To demonstrate barycentric coordinates, we have the following image:
        </p>
        <figure>
			<img src="rgb_tri.png" style="width:50%"/>
			<figcaption>Triangle, with corners assigned their own color channels.</figcaption>
		</figure>
        <p>
        In this triangle, we have a red, green, and blue corner. 
        If we treat the 'proportion' of each corner in the samples' barycentric coordinates as the respective red, green, and blue values of the sample, we get the above image. 
        With this understanding, it is clear that every sample location inside the triangle can be represented as some combination of the three corner positions.
        </p>

        <figure>
			<img src="test7_gradient.png" style="width:50%"/>
			<figcaption>Test7 Screenshot</figcaption>
		</figure>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
        <p>
            While drawing triangles with solid or interpolated colors is nice, pixel sampling allows us to apply a texture across the surface of a triangle. 
            This makes it much easier to create significantly more detail with the same amount of geometry.
            At a high level, pixel sampling involves taking some coordinates, transforming them to the space of a discrete function, and using the sample of that function at the transformed position as the value of the posiiton in the original space.
            In our 'texture mapping' case, the discrete function will be a texture, with pixels defined at integer coordinates for some rectangular width and height. 
            Additionally, we'll be transforming from the screen space to the texture's own space to sample the texture's pixels.
        </p>
        <p>
            We'll be implementing two pixel sampling methods: nearest-neighbor and bilinear.
            Nearest-neightbor simply rounds the transformed coordinates to the nearest pixel coordinates in the texture, and returns the color value of that pixel.
            Bilinear sampling instead performs a linear interpolation on the closest texture pixels the transformed coordinate lies between. 
            This provides a smoother result, as the returned color is a weighted average of the surrounding pixels.
        </p>
        <p>
            To actually implement pixel sampling, we'll re-use the barycentric calculations from Task 4. 
            Since our triangle-rasterizing function is given both screen space x,y coordinates and texture space u,v coordinates, a barycentric representation of a sample's coordinates will allow us to easily transform between the two spaces.
            This is because the 'proportion' of each triangle point in a coordinate should remain the same, regardless of any rotation, scaling, or translation effects resulting from transforming between the two spaces.
            Then, just like in task 2, we precompute some values, in this case transformation matricies, apply the barycentric transformation to every sample point, and sample the specified texture at that point, using one of the above coordinates.
            Note that, when implementing the texture sampling functions, we have to scale provided u,v coordinates by the texture's width and height, respectively, as the u,v coordinates are provided in a normalized format.
        </p>

        (IMAGES)

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
        <p>
            The bilinear mode of our texture mapping implementation handles magnified textures quite well. 
            However, we don't yet have a solution for minified textures.
            When we sample a large texture at only a few points, we quickly run into artifacts like Moire patterns due to our sampling rate being much lower than highest frequencies present within the image.
            In other words, having a large texture cover only a few screen pixels results in us exceeding the Nyquist frequency. 
        </p>
        <p>
            To fix this, one option is to reduce the presence of high frequencies in the texture we are sampling when it is being used to cover only a small area.
            This is where mipmaps and level sampling come in, as they allow us to do exactly that.
            Mipmaps are essentially lower resolution copies of a texture, which have been downsampled to incrementally eliminate higher frequencies.
            For each texture, we'll compute several 'levels' of mipmaps, each downsampled further than the last.
            Then, when rasterizing, we can select which level of mipmap to sample from depending on the area covered by the texture in screen space.
            This selection process is known as level sampling.
        </p>
        <p>
            To actually implement level sampling, we have to be able to do two things. 
            First is determining which mipmap level should be used for a given sample. 
            To do this, we pass in not just the uv coordinates of the sample position, but also the uv coordinates of that position shifted by 1 pixel along the screen space axes.
            Thus, we'll also pass in two copies of the uv coordinates, one shifted by 1 along the x-axis, and one shifted by 1 along the y-axis.
            Using the difference of the shifted uv coordinates and the original uv sample coordinates, we can determine how many pixels a one pixel step in the screen space covers in the texture space, and choose a downsampled mipmap accordingly.
            Since the xy and uv axes may not line up exactly, we focus on the magnitudes of the 'step' vectors in texture space. 
            By choosing the maximum of these vectors, we guarantee that our selected mipmap will not have frequencies exceeding screen's sampling rate.
            Also, since our downsampling implementation halves the resolution of the textures with each level, we want to take the base 2 logarithm of this maximum to get an accurate magnitude-to-level conversion.
            However, this leaves us with a potentially fractional level value.
            To fix this, we can either round or interpolate between levels.
        </p>
        <p>
            Rounding, or nearest-level approximation is straightforward. 
            We just take the ceiling of the floating-point level value produced in the previous steps, and sample from that mipmap texture as in Task 5.
            Note that we use the ceiling here instead of true rounding, since we need to ensure that all frequencies present in the mipmap are below the Nyquist threshold.
            Additionally, we scale the uv coordinates by the width and height of the mipmap, instead of the overall texture's dimensions.
        </p>
        <p>
            If we instead want to linearly interpolate between the integer levels surrounding our floating point value, we begin by sampling both the levels at the floor and ceiling of the initial floating-point level value.
            This proceeds as in Task 5, using either nearest-neighbor or bilinear sampling for both levels.
            Once we have both colors, we linearly interpret between them, using the intial floating point value.
        </p>

        (IMAGES + COMPARISON)


		<h2>(Optional) Task 7: Extra Credit - Draw Something Creative!</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>